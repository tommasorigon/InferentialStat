<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tommaso Rigon">

<title>Point estimation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="un_A_files/libs/clipboard/clipboard.min.js"></script>
<script src="un_A_files/libs/quarto-html/quarto.js"></script>
<script src="un_A_files/libs/quarto-html/popper.min.js"></script>
<script src="un_A_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="un_A_files/libs/quarto-html/anchor.min.js"></script>
<link href="un_A_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="un_A_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="un_A_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="un_A_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="un_A_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#homepage" id="toc-homepage" class="nav-link active" data-scroll-target="#homepage">Homepage</a></li>
  <li><a href="#methods-of-finding-estimators" id="toc-methods-of-finding-estimators" class="nav-link" data-scroll-target="#methods-of-finding-estimators">Methods of finding estimators</a>
  <ul class="collapse">
  <li><a href="#estimator" id="toc-estimator" class="nav-link" data-scroll-target="#estimator">Estimator</a></li>
  <li><a href="#method-of-moments" id="toc-method-of-moments" class="nav-link" data-scroll-target="#method-of-moments">Method of moments</a></li>
  <li><a href="#asymptotic-evaluation-of-the-mm" id="toc-asymptotic-evaluation-of-the-mm" class="nav-link" data-scroll-target="#asymptotic-evaluation-of-the-mm">Asymptotic evaluation of the MM</a></li>
  <li><a href="#example-beta-method-of-moments" id="toc-example-beta-method-of-moments" class="nav-link" data-scroll-target="#example-beta-method-of-moments">✏ Example: beta method of moments</a></li>
  <li><a href="#maximum-likelihood-estimator" id="toc-maximum-likelihood-estimator" class="nav-link" data-scroll-target="#maximum-likelihood-estimator">Maximum likelihood estimator</a></li>
  <li><a href="#properties-and-remarks-about-the-mle" id="toc-properties-and-remarks-about-the-mle" class="nav-link" data-scroll-target="#properties-and-remarks-about-the-mle">Properties and remarks about the MLE</a></li>
  <li><a href="#a-regular-and-very-simple-example" id="toc-a-regular-and-very-simple-example" class="nav-link" data-scroll-target="#a-regular-and-very-simple-example">✏ A regular (and very simple) example</a></li>
  <li><a href="#a-non-regular-example" id="toc-a-non-regular-example" class="nav-link" data-scroll-target="#a-non-regular-example">✏ A non-regular example</a></li>
  <li><a href="#m-estimators" id="toc-m-estimators" class="nav-link" data-scroll-target="#m-estimators">M-estimators</a></li>
  <li><a href="#z-estimators" id="toc-z-estimators" class="nav-link" data-scroll-target="#z-estimators">Z-estimators</a></li>
  <li><a href="#huber-estimators-i" id="toc-huber-estimators-i" class="nav-link" data-scroll-target="#huber-estimators-i">Huber estimators I</a></li>
  <li><a href="#huber-estimators-ii" id="toc-huber-estimators-ii" class="nav-link" data-scroll-target="#huber-estimators-ii">Huber estimators II</a></li>
  <li><a href="#bayesian-estimators" id="toc-bayesian-estimators" class="nav-link" data-scroll-target="#bayesian-estimators">Bayesian estimators</a></li>
  <li><a href="#another-regular-and-very-simple-example" id="toc-another-regular-and-very-simple-example" class="nav-link" data-scroll-target="#another-regular-and-very-simple-example">✏ Another regular (and very simple) example</a></li>
  </ul></li>
  <li><a href="#methods-of-evaluating-estimators" id="toc-methods-of-evaluating-estimators" class="nav-link" data-scroll-target="#methods-of-evaluating-estimators">Methods of evaluating estimators</a>
  <ul class="collapse">
  <li><a href="#comparing-estimators" id="toc-comparing-estimators" class="nav-link" data-scroll-target="#comparing-estimators">Comparing estimators</a></li>
  </ul></li>
  <li><a href="#best-unbiased-estimators" id="toc-best-unbiased-estimators" class="nav-link" data-scroll-target="#best-unbiased-estimators">Best unbiased estimators</a></li>
  <li><a href="#asymptotic-evaluations" id="toc-asymptotic-evaluations" class="nav-link" data-scroll-target="#asymptotic-evaluations">Asymptotic evaluations</a>
  <ul class="collapse">
  <li><a href="#consistency-and-asymptotic-normality" id="toc-consistency-and-asymptotic-normality" class="nav-link" data-scroll-target="#consistency-and-asymptotic-normality">Consistency and asymptotic normality</a></li>
  <li><a href="#the-regularity-conditions" id="toc-the-regularity-conditions" class="nav-link" data-scroll-target="#the-regularity-conditions">The “regularity conditions”</a></li>
  <li><a href="#asymptotics-for-the-mle" id="toc-asymptotics-for-the-mle" class="nav-link" data-scroll-target="#asymptotics-for-the-mle">Asymptotics for the MLE</a></li>
  </ul></li>
  <li><a href="#robustness" id="toc-robustness" class="nav-link" data-scroll-target="#robustness">Robustness</a>
  <ul class="collapse">
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="un_A_slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></nav>
</div>
<main class="content page-columns page-full column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Point estimation</h1>
<p class="subtitle lead">Statistical Inference - PhD EcoStatData</p>
</div>


<div class="quarto-title-meta-author column-page-left">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><span class="orange">Tommaso Rigon</span> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <em>Università degli Studi di Milano-Bicocca</em>
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-page-left">

      
  
    
  </div>
  


</header>


<section id="homepage" class="level2">
<h2 class="anchored" data-anchor-id="homepage"><a href="../index.html">Homepage</a></h2>
<div class="columns">
<div class="column" style="width:20%;">
<p><img src="img/target.png" class="img-fluid"></p>
<!-- *"Pluralitas non est ponenda sine necessitate."* -->
<!-- [William of Ockham]{.grey} -->
</div><div class="column" style="width:80%;">
<ul>
<li><p>This unit will cover the following <span class="orange">topics</span>:</p>
<ul>
<li>Methods of finding estimators</li>
<li>Methods of evaluating estimators</li>
<li>Best unbiased estimators</li>
<li>Asymptotic evaluations</li>
<li>Robustness and model misspecification</li>
</ul></li>
</ul>
</div>
</div>
<ul>
<li><p>The rational behind <span class="blue">point estimation</span> is quite simple:</p></li>
<li><p>When sampling is from a <span class="orange">population</span> described by a pdf or a pmf <span class="math inline">f(\cdot ; \theta)</span>, knowledge of <span class="math inline">\theta</span> yields knowledge of the entire population.</p></li>
<li><p>Hence, it is natural to seek a method of finding a good <span class="blue">estimator</span> of the unknown point <span class="math inline">\theta</span>.</p></li>
</ul>
</section>
<section id="methods-of-finding-estimators" class="level1 page-columns page-full">
<h1>Methods of finding estimators</h1>
<section id="estimator" class="level2">
<h2 class="anchored" data-anchor-id="estimator">Estimator</h2>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Point estimator
</div>
</div>
<div class="callout-body-container callout-body">
<p>A <span class="blue">point estimator</span> <span class="math inline">\hat{\theta}</span> is any function of the random sample <span class="math inline">Y_1,\dots,Y_n</span>, namely <span class="math display">
\hat{\theta}(\bm{Y}) = \hat{\theta}(Y_1,\dots,Y_n).
</span> That is, any <span class="orange">statistic</span> is a point estimator.</p>
</div>
</div>
<ul>
<li><p>In principle, the range of the estimator coincide with that of the parameter, i.e.&nbsp;<span class="math inline">\hat{\theta} : \mathcal{Y} \rightarrow \Theta</span>, but there are exceptions.</p></li>
<li><p>An <span class="blue">estimator</span> <span class="math inline">\hat{\theta}(Y_1,\dots,Y_n)</span> is a function of the sample <span class="math inline">Y_1,\dots,Y_n</span> and is a <span class="blue">random variable</span>.</p></li>
<li><p>An <span class="orange">estimate</span> <span class="math inline">\hat{\theta}(y_1,\dots,y_n)</span> is a function of the realized values <span class="math inline">y_1,\dots,y_n</span> and is a <span class="orange">number</span>.</p></li>
<li><p>We will use the notation <span class="math inline">\hat{\theta}</span> to denote both estimators and estimates whenever its meaning is clear from the context.</p></li>
</ul>
</section>
<section id="method-of-moments" class="level2">
<h2 class="anchored" data-anchor-id="method-of-moments">Method of moments</h2>
<ul>
<li><p>The <span class="blue">methods of moments</span> is, perhaps, the oldest method of finding point estimators, dating back at least to Karl Pearson in the late 1800s.</p></li>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid sample from <span class="math inline">f(\cdot; \theta)</span> and <span class="math inline">\theta = (\theta_1,\dots,\theta_p)</span>. Moreover, let us define <span class="math display">
m_r = \frac{1}{n}\sum_{i=1}^n Y_i^r, \qquad \mu_r(\theta) = \mu_r(\theta_1,\dots,\theta_p) = \mathbb{E}_\theta(Y^r), \qquad r=1,\dots,p.
</span> corresponding to the <span class="blue">population moment</span> <span class="math inline">\mu_r(\theta_1,\dots,\theta_p)</span> and the <span class="orange">sample moment</span> <span class="math inline">m_r</span>.</p></li>
<li><p>The method of moments estimator <span class="math inline">\hat{\theta}</span> is obtained by solving the following system of equations for <span class="math inline">(\theta_1,\dots,\theta_p)</span>: <span class="math display">
\begin{aligned}
\mu_1(\theta_1,\dots,\theta_p) &amp;= m_1, \\
\mu_2(\theta_1,\dots,\theta_p) &amp;= m_2, \\
&amp;\vdots \\
\mu_p(\theta_1,\dots,\theta_p) &amp;= m_p. \\
\end{aligned}
</span></p></li>
<li><p>In general, it is <span class="orange">not guaranteed</span> that a <span class="blue">solution exist</span> nor its <span class="blue">uniqueness</span>.</p></li>
</ul>
</section>
<section id="asymptotic-evaluation-of-the-mm" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="asymptotic-evaluation-of-the-mm">Asymptotic evaluation of the MM</h2>
<ul>
<li><p>Moments estimators are not necessarily the best estimators, but <span class="blue">under reasonable conditions</span> they are <span class="orange">consistent</span>, they have converge rate <span class="math inline">\sqrt{n}</span>, and they are <span class="orange">asymptotically normal</span>.</p></li>
<li><p>Suppose <span class="math inline">(Y,Y^2,\dots,Y^p)</span> has finite covariance <span class="math inline">\Sigma</span>, then the multivariate <span class="orange">central limit theorem</span> implies that as <span class="math inline">n\rightarrow \infty</span> <span class="math display">
\sqrt{n}\{m - \mu(\theta)\} \overset{d}{\longrightarrow} Z, \qquad Z\sim N_p(0, \Sigma),
</span> where <span class="math inline">m = (m_1,\dots,m_p)</span> and <span class="math inline">\mu(\theta) = (\mu_1(\theta),\dots,\mu_p(\theta))</span>.</p></li>
<li><p>Suppose also that <span class="math inline">\mu(\theta)</span> is a <span class="blue">one-to-one</span> mapping and let <span class="math inline">g(\mu)</span> be the inverse of <span class="math inline">\mu(\theta)</span>, that is <span class="math inline">g = \mu^{-1}</span>. We assume that <span class="math inline">g</span> has <span class="blue">differentiable</span> components <span class="math inline">g_r(\cdot)</span> for <span class="math inline">r = 1,\dots,p</span>.</p></li>
<li><p>The moments estimator can be written as <span class="math inline">\hat{\theta} = g(m)</span> and <span class="math inline">\theta = g(\mu(\theta))</span>. Then, as a consequence of the <span class="orange">delta method</span> the following general result holds: <span class="math display">
\sqrt{n}(\hat{\theta} - \theta) \overset{d}{\longrightarrow} Z, \qquad Z\sim N_p\left(0, D \Sigma D^T\right),
</span> where <span class="math inline">D = [d_{rr'}]</span> is a <span class="math inline">p \times p</span> matrix whose entries are the derivatives <span class="math inline">d_{rr'} = \partial g_r(\mu)/\partial \mu_{r'}</span>.</p></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<p>Refer to <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#ref-vandervaart1998" role="doc-biblioref">1998</a>)</span>, Theorem 4.1, pag. 35-36.</p>
</div></div></section>
<section id="example-beta-method-of-moments" class="level2">
<h2 class="anchored" data-anchor-id="example-beta-method-of-moments">✏ Example: beta method of moments</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid random sample from a beta distribution of parameters <span class="math inline">\alpha,\beta &gt; 0</span> with density <span class="math display">
f(y; \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} y^{\alpha-1}(1 - y)^{\beta-1}, \qquad 0 &lt; y &lt; 1.
</span></p></li>
<li><p>The <span class="blue">moment estimator</span> for <span class="math inline">(\alpha, \beta)</span> is the (<span class="orange">explicitly available</span>) solution of the system of equations <span class="math display">
m_1 = \frac{\alpha}{\alpha + \beta}, \qquad m_2 = \frac{\alpha (\alpha+1)}{(\alpha + \beta) (\alpha + \beta + 1)}.
</span></p></li>
</ul>
<ul>
<li>After some algebra we obtain the following relationship, which is a <span class="orange">smooth</span> and <span class="orange">regular</span> function of <span class="math inline">(m_1,m_2)</span>: <span class="math display">
\hat{\alpha} = m_1 \frac{m_1 - m_2}{m_2 - m_1^2}, \qquad \hat{\beta} = (1 - m_1) \frac{m_1 - m_2}{m_2 - m_1^2}.
</span> where <span class="math inline">\hat{\sigma}^2 = m_2 - m_1^2</span> is the <span class="blue">sample variance</span>. <span class="orange">Remark</span>: what if <span class="math inline">m_1 &lt; m_2</span>?</li>
</ul>
</section>
<section id="maximum-likelihood-estimator" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimator">Maximum likelihood estimator</h2>
<ul>
<li><p>The method of <span class="orange">maximum likelihood</span> is, by far, the most popular technique for deriving estimators, developed by <span class="blue">Ronald A. Fisher</span> in Fisher (1922; 1925).</p></li>
<li><p>Recall that <span class="math inline">L(\theta) = L(\theta; \bm{y})</span> is the likelihood function and <span class="math inline">\ell(\theta) = \log{L(\theta)}</span> is the log-likelihood.</p></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Given a likelihood function <span class="math inline">L(\theta)</span> of <span class="math inline">\theta \in \Theta</span>, a <span class="orange">maximum likelihood estimate</span> of <span class="math inline">\theta</span> is an element <span class="math inline">\hat{\theta} \in \Theta</span> which attains the maximum value of <span class="math inline">L(\theta)</span> in <span class="math inline">\Theta</span>, i.e.&nbsp;such that <span class="math inline">L(\hat{\theta}) \ge L(\theta)</span> or equivalently <span class="math display">
L(\hat{\theta}) = \max_{\theta \in \Theta} L(\theta).
</span></p>
<p>The <span class="blue">maximum likelihood estimator</span> (MLE) of the parameter <span class="math inline">\theta</span> based on a sample <span class="math inline">\bm{Y}</span> is <span class="math inline">\hat{\theta}(\bm{Y})</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>Intuitively, the MLE is a reasonable choice: it is the parameter point for which the observed sample is <span class="blue">most likely</span>.</p></li>
<li><p>Clearly, the MLE is also the maximizer of the log-likelihood: <span class="math inline">\ell(\hat{\theta}) = \max_{\theta \in \Theta} \ell(\theta)</span>.</p></li>
</ul>
</section>
<section id="properties-and-remarks-about-the-mle" class="level2">
<h2 class="anchored" data-anchor-id="properties-and-remarks-about-the-mle">Properties and remarks about the MLE</h2>
<ul>
<li><span class="blue">Remark I</span>: the MLE may <span class="orange">not exists</span> and is <span class="orange">not</span> necessarily <span class="orange">unique</span>. On the other hand, if <span class="math inline">l(\theta)</span> is differentiable, then it can be found as the solution of the <span class="blue">score equations</span>: <span class="math display">
\ell^*(\theta) = \frac{\partial}{\partial \theta}\ell(\theta) = 0.
</span></li>
</ul>
<!-- - If $s(y)$ is a [sufficient statistic]{.blue}, then the MLE is a function of it. -->
<ul>
<li><p><span class="blue">Remark II</span>: often <span class="math inline">\hat{\theta}</span> cannot be written explicitly as a function of the sample values, i.e.&nbsp;in general the MLE has <span class="orange">no closed-form expression</span> but it must be found using <span class="orange">numerical procedures</span>.</p></li>
<li><p><span class="blue">Remark III</span>: the likelihood function has to be maximized in the set space <span class="math inline">\Theta</span> specified by the statistical model, not over the set of the mathematically admissible values of <span class="math inline">\theta</span>.</p></li>
</ul>
<!-- - [Remark IV]{.blue}: it is not necessary for $\Theta$ to be a numeric set, i.e. we need [not]{.orange} be dealing with a [parametric]{.orange} model, although we shall restrict ourself to this case. -->
<div class="callout callout-style-simple callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Theorem <span class="citation" data-cites="Casella2002">(Invariance, <a href="#ref-Casella2002" role="doc-biblioref">Casella and Berger 2002</a>, Theorem 7.2.10)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">\psi(\cdot)</span> be a one-to-one function (i.e.&nbsp;a <span class="blue">reparametrization</span>) from the set <span class="math inline">\Theta</span> onto the set <span class="math inline">\Psi</span>. Then the MLE of <span class="math inline">\psi = \psi(\theta)</span> is <span class="math inline">\hat{\psi} = \psi(\hat{\theta})</span> where <span class="math inline">\hat{\theta}</span> denotes the MLE of <span class="math inline">\theta</span>.</p>
</div>
</div>
</section>
<section id="a-regular-and-very-simple-example" class="level2">
<h2 class="anchored" data-anchor-id="a-regular-and-very-simple-example">✏ A regular (and very simple) example</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a iid random sample from a Poisson distribution of parameter <span class="math inline">\lambda &gt; 0</span>, with <span class="orange">likelihood function</span> <span class="math display">
L(\lambda) = \prod_{i=1}^n \frac{e^{-\lambda} \lambda^{y_i}}{y_i!}.
</span></p></li>
<li><p>Therefore the <span class="blue">log-likelihood</span>, up to an additive constant <span class="math inline">c</span> not depending on <span class="math inline">\lambda</span>, is <span class="math display">
\ell(\lambda) = \sum_{i=1}^ny_i\log{\lambda} - n\lambda + c.
</span></p></li>
<li><p>The <span class="orange">maximum likelihood estimator</span> <span class="math inline">\hat{\lambda}</span> is found by maximizing <span class="math inline">\ell(\lambda)</span>. In this regular problem, this can be done by studying the first derivative: <span class="math display">
\ell^*(\lambda) = \frac{1}{\lambda}\sum_{i=1}^ny_i - n.
</span></p></li>
<li><p>We solve <span class="math inline">\ell^*(\lambda) = 0</span>, obtaining <span class="math inline">\hat{\lambda} = \bar{y}</span>. This is indeed a maximizer of <span class="math inline">\ell(\lambda)</span> (<span class="orange">why</span>?).</p></li>
</ul>
</section>
<section id="a-non-regular-example" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="a-non-regular-example">✏ A non-regular example</h2>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<p>This problem is described in Example 7.2.2 <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#ref-Casella2002" role="doc-biblioref">2002</a>)</span>, pag. 313.</p>
</div></div></section>
<section id="m-estimators" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="m-estimators">M-estimators</h2>
<ul>
<li>M- and Z- estimators are broad class of estimators that encompass the maximum likelihood (iid observations) and other popular methods as special cases. <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;See Exercise 10.28 of <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#ref-Casella2002" role="doc-biblioref">2002</a>)</span>.</p></div></div><div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>An <span class="blue">M-estimator</span> is the <span class="orange">maximizer</span> over <span class="math inline">\Theta</span> of a function <span class="math inline">M(\theta) : \Theta \rightarrow \mathbb{R}</span> of the type: <span class="math display">
M(\theta) = \frac{1}{n}\sum_{i=1}^n m(\theta; Y_i),
</span> where <span class="math inline">m(\theta; Y_i)</span> are known real-valued functions.</p>
</div>
</div>
</div>
<ul>
<li><p><span class="orange">Remark</span>: when <span class="math inline">m(\theta; y) = \log{f(Y_i; \theta)}</span> this coincides with the MLE of a model with iid observations.</p></li>
<li><p>The term <span class="math inline">1/n</span> is included here to facilitate the description of the subsequent asymptotic theory, but it is obviously non influential.</p></li>
</ul>
</section>
<section id="z-estimators" class="level2">
<h2 class="anchored" data-anchor-id="z-estimators">Z-estimators</h2>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>A <span class="blue">Z-estimator</span> is the <span class="orange">solution</span> over <span class="math inline">\Theta</span> of a system of equations function <span class="math inline">Q(\theta) = \bm{0}</span> of the type: <span class="math display">
Q(\theta) = Q(\theta; Y) = \frac{1}{n}\sum_{i=1}^n q(\theta; Y_i) = \bm{0},
</span> where <span class="math inline">q(y; \theta)</span> are known vector-valued maps. These are called <span class="blue">estimating equations</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>When <span class="math inline">\theta = (\theta_1,\dots,\theta_p)</span>, <span class="math inline">Q</span> and <span class="math inline">q</span> typically have <span class="math inline">p</span> coordinate functions, namely we consider: <span class="math display">
Q_r(\theta) = \frac{1}{n}\sum_{i=1}^n q_r(\theta; Y_i)= 0, \qquad r = 1,\dots,p.
</span></p></li>
<li><p>In many examples <span class="math inline">q_r(y; \theta)</span> are the partial derivatives of a function <span class="math inline">m(\theta; y)</span>, that is <span class="math display">
Q(\theta) = \frac{\partial}{\partial \theta} M(\theta).</span> An example is the <span class="blue">score function</span> <span class="math inline">\ell^*(\theta)</span>. However, this is <span class="orange">not always the case</span>.</p></li>
</ul>
<!-- ## Plug-in estimators -->
</section>
<section id="huber-estimators-i" class="level2">
<h2 class="anchored" data-anchor-id="huber-estimators-i">Huber estimators I</h2>
<ul>
<li><p>The <span class="orange">location</span> of a r.v. <span class="math inline">Y</span> is a vague term that can be made precise by defining it as the expectation <span class="math inline">\mathbb{E}(Y)</span>, a quantile, or the center of symmetry, as in the following example.</p></li>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a iid sample of real-valued random variables belonging to family of distributions <span class="math inline">\mathcal{F}</span> defined as <span class="math display">
\mathcal{F} = \{f(y - \theta) : \theta \in \Theta \subseteq \mathbb{R} \},
</span> for some unknown density <span class="math inline">f(y)</span> <span class="blue">symmetric</span> around <span class="math inline">0</span>. The parameter <span class="math inline">\theta</span> is the <span class="orange">location</span>.</p></li>
<li><p>Classical M- estimators for <span class="math inline">\theta</span> are the <span class="blue">mean</span> and the <span class="orange">median</span>, maximizing: <span class="math display">
-\frac{1}{n}\sum_{i=1}^n (Y_i - \theta)^2, \quad (\text{Mean}) \qquad \qquad - \frac{1}{n}\sum_{i=1}^n |Y_i - \theta|, \quad (\text{Median})
</span> or alternatively (Z- estimator forms) solving the equations <span class="math display">
\frac{1}{n}\sum_{i=1}^n (Y_i - \theta) = 0, \quad (\text{Mean}) \qquad \qquad \frac{1}{n}\sum_{i=1}^n \text{sign}(Y_i - \theta) = 0, \quad (\text{Median}).
</span></p></li>
</ul>
<!-- ## Location estimators II -->
<!-- - Both estimating equations involve functions of the form $q(\theta; Y) = q(Y - \theta)$ that are [monotone]{.blue} and [odd]{.orange} around zero.  -->
<!-- - It is hence reasonable to study estimating equations of the type:$$ -->
<!-- Q(\theta) = \frac{1}{n}\sum_{i=1}^n q(Y_i - \theta)= 0. -->
<!-- $$ -->
<!-- - This class of estimators has an appealing [equivariance]{.orange} property. If the observations $Y_i$ are shifted by a fixed amount $\alpha$, then so is the estimate: -->
<!-- $$ -->
<!-- \hat{\theta} + \alpha \quad \text{ solves } \quad Q(\theta) = \frac{1}{n}\sum_{i=1}^n q(Y_i + \alpha - \theta)= 0, -->
<!-- $$ -->
<!-- if $\hat{\theta}$ solves the original equation. -->
</section>
<section id="huber-estimators-ii" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="huber-estimators-ii">Huber estimators II</h2>
<ul>
<li><p><span class="blue">Huber estimators</span> can be regarded as a compromise between the mean and the median, maximizing the following function: <span class="math display">
M(\theta) = \frac{1}{n}\sum_{i=1}^n m(Y_i - \theta), \qquad m(y) = \begin{cases}\frac{1}{2}y^2 \quad &amp;\text{ if } |y| \le k\\
k |y| - \frac{1}{2}k^2 \quad &amp;\text{ if } |y| \ge k
\end{cases}
</span> where <span class="math inline">k &gt; 0</span> is a <span class="orange">tuning</span> parameter. The function <span class="math inline">m(y)</span> is continuous and differentiable<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. The choice <span class="math inline">k \rightarrow 0</span> leads to the median, whereas for <span class="math inline">k \rightarrow \infty</span> we get the mean.</p></li>
<li><p>Equivalently, we can consider the solution of the following estimating equation: <span class="math display">
Q(\theta) = \frac{1}{n}\sum_{i=1}^n q(Y_i - \theta)= 0, \qquad q(y) = \begin{cases} -k \quad &amp;\text{ if }\: y \le -k\\
y \quad &amp;\text{ if  }\: |y| \le k \\
k \quad &amp;\text{ if }\: y \ge k\end{cases}
</span></p></li>
<li><p>Unfortunately, there is no closed-form expression and the equation must be solved numerically.</p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;See Exercise 10.28 of <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#ref-Casella2002" role="doc-biblioref">2002</a>)</span>.</p></div></div></section>
<section id="bayesian-estimators" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-estimators">Bayesian estimators</h2>
<ul>
<li><p>Bayesian estimators are obtained following <span class="orange">different inferential paradigm</span> than the one considered here, but they also have <span class="blue">appealing frequentist properties</span>.</p></li>
<li><p>Let <span class="math inline">L(\theta; \bm{y})</span> be the likelihood function and let <span class="math inline">\pi(\theta)</span> be the <span class="orange">prior</span> distribution. Then, Bayesian inference relies on the <span class="blue">posterior</span> distribution, obtained as <span class="math display">
\pi(\theta \mid \bm{y}) = \frac{\pi(\theta) L(\theta; \bm{y})}{\int_\Theta \pi(\theta) L(\theta; \bm{y}) \mathrm{d}\theta}.
</span></p></li>
<li><p>For reasons that will be soon clarified, under certain hypothesis the <span class="blue">posterior mean</span> is an <span class="orange">optimal Bayesian estimator</span>: <span class="math display">
\hat{\theta}_\text{Bayes} = \mathbb{E}(\theta \mid \bm{y}) = \frac{\int_\Theta \theta \: \pi(\theta) L(\theta; \bm{y}) \mathrm{d}\theta}{\int_\Theta \pi(\theta) L(\theta; \bm{y}) \mathrm{d}\theta},
</span> which is, unfortunately, not always available in closed-form.</p></li>
<li><p>Other “optimal” Bayesian estimators include e.g.&nbsp;the posterior median.</p></li>
</ul>
</section>
<section id="another-regular-and-very-simple-example" class="level2">
<h2 class="anchored" data-anchor-id="another-regular-and-very-simple-example">✏ Another regular (and very simple) example</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a iid random sample from a Poisson distribution of parameter <span class="math inline">\lambda &gt; 0</span>, with <span class="orange">likelihood function</span> <span class="math display">
L(\lambda) = \prod_{i=1}^n \frac{e^{-\lambda} \lambda^{y_i}}{y_i!}.
</span></p></li>
<li><p>Therefore the <span class="blue">log-likelihood</span>, up to an additive constant <span class="math inline">c</span> not depending on <span class="math inline">\lambda</span>, is <span class="math display">
\ell(\lambda) = \sum_{i=1}^ny_i\log{\lambda} - n\lambda + c.
</span></p></li>
<li><p>The <span class="orange">maximum likelihood estimator</span> <span class="math inline">\hat{\lambda}</span> is found by maximizing <span class="math inline">\ell(\lambda)</span>. In this regular problem, this can be done by studying the first derivative: <span class="math display">
\ell^*(\lambda) = \frac{1}{\lambda}\sum_{i=1}^ny_i - n.
</span></p></li>
<li><p>We solve <span class="math inline">\ell^*(\lambda) = 0</span>, obtaining <span class="math inline">\hat{\lambda} = \bar{y}</span>. This is indeed a maximizer of <span class="math inline">\ell(\lambda)</span> (<span class="orange">why</span>?).</p></li>
</ul>
</section>
</section>
<section id="methods-of-evaluating-estimators" class="level1">
<h1>Methods of evaluating estimators</h1>
<section id="comparing-estimators" class="level2">
<h2 class="anchored" data-anchor-id="comparing-estimators">Comparing estimators</h2>
</section>
</section>
<section id="best-unbiased-estimators" class="level1">
<h1>Best unbiased estimators</h1>
</section>
<section id="asymptotic-evaluations" class="level1">
<h1>Asymptotic evaluations</h1>
<section id="consistency-and-asymptotic-normality" class="level2">
<h2 class="anchored" data-anchor-id="consistency-and-asymptotic-normality">Consistency and asymptotic normality</h2>
</section>
<section id="the-regularity-conditions" class="level2">
<h2 class="anchored" data-anchor-id="the-regularity-conditions">The “regularity conditions”</h2>
</section>
<section id="asymptotics-for-the-mle" class="level2">
<h2 class="anchored" data-anchor-id="asymptotics-for-the-mle">Asymptotics for the MLE</h2>
</section>
</section>
<section id="robustness" class="level1">
<h1>Robustness</h1>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Casella2002" class="csl-entry" role="listitem">
Casella, George, and Roger L. Berger. 2002. <em><span>Statistical Inference</span></em>. Duxbury.
</div>
<div id="ref-vandervaart1998" class="csl-entry" role="listitem">
van der Vaart, A. W. 1998. <em><span>Asymptotic Statistics</span></em>. Cambridge University Press.
</div>
</div>
</section>
</section>


</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<script src="un_A_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>