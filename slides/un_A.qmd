---
title: "Point estimation"
subtitle: "Statistical Inference - PhD EcoStatData"
author: "[Tommaso Rigon]{.orange}"
institute: "_Universit√† degli Studi di Milano-Bicocca_"
page-layout: full
execute:
  cache: false
filters: 
  - remove-pause.lua
format:
  revealjs:
    auto-stretch: true
    center: true
    html-math-method: katex
    transition: none
    output-file: un_A_slides.html
    slide-number: true
    callout-appearance: minimal
    code-line-numbers: true
    theme: [default, ../template.css] # alternative themes (subset): default, night, dark
    embed-resources: false
    echo: false
    fig-dpi: 200
    # incremental: true  # Remove comment if you like incremental bullet points
    logo: img/logoB.png
    footer: "[Home page](https://tommasorigon.github.io/InferentialStat)"
    highlight-style: github
  html:
    html-math-method: katex
    echo: false
    callout-appearance: minimal
    theme: [simplex, ../template.css]
    toc: true
    toc-title: Table of contents
    embed-resources: false
    code-line-numbers: true
    smooth-scroll: true
    code-fold: false
    code-summary: "Show the code"
    fig-dpi: 150
    highlight-style: github
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---


## [Homepage](../index.html)

```{r}
#| warning: false
#| echo: false
#| include: false
#| message: false
#| purl: false

knitr::purl("un_A.qmd", output = "../code/un_A.R", documentation = 0)
styler:::style_file("../code/un_A.R")
```

::: columns
::: {.column width="30%"}
![](img/target.png)

<!-- *"Pluralitas non est ponenda sine necessitate."* -->

<!-- [William of Ockham]{.grey} -->
:::

::: {.column width="70%"}
- This unit will cover the following [topics]{.orange}:

    - Methods of finding estimators
    - Methods of evaluating estimators
    - Best unbiased estimators
    - Asymptotic behavior
    - Robustness and model misspecification

- The rational behind [point estimation]{.blue} is quite simple: 

- When sampling is from a [population]{.orange} described by a pdf or a pmf $f(\cdot ; \theta)$, knowledge of $\theta$ yields knowledge of the entire population.

- Hence, it is natural to seek a method of finding a good [estimator]{.blue} of the unknown point $\theta$.
:::
:::

# Methods of finding estimators

## Estimator

::: callout-note
#### Point estimator

A [point estimator]{.blue} $\hat{\theta}$ is any function of the random sample $Y_1,\dots,Y_n$, namely
$$
\hat{\theta}(\bm{Y}) = \hat{\theta}(Y_1,\dots,Y_n).
$$
That is, any [statistic]{.orange} is a point estimator.
:::

- In principle, the range of the estimator coincide with that of the parameter, i.e.  $\hat{\theta} : \mathcal{Y} \rightarrow \Theta$, but there are exceptions. 
- An [estimator]{.blue} $\hat{\theta}(Y_1,\dots,Y_n)$ is a function of the sample $Y_1,\dots,Y_n$ and  is a [random variable]{.blue}.

- An [estimate]{.orange} $\hat{\theta}(y_1,\dots,y_n)$ is a function of the realized values $y_1,\dots,y_n$ and is a [number]{.orange}. 

- We will use the notation $\hat{\theta}$ to denote both estimators and estimates whenever its meaning is clear from the context.

## Methods of moments

- The [methods of moments]{.blue} is, perhaps, the oldest method of finding point estimators, dating back at least to Karl Pearson in the late 1800s.

## Example I: binomial method of moments

- asd

## Asymptotics

## Maximum likelihood

## M- and Z- estimators

## Plug-in estimators

## Bayesian estimators

# Methods of evaluating estimators

# Best unbiased estimators

# Asymptotic behavior

# Robustness